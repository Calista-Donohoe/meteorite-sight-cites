{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "file_path_cham = \"cleaned_cham_api_1900_1963.csv\"\n",
    "file_path_meteorites = \"meteorites_with_state_and_country.csv\"\n",
    "\n",
    "# Reading the data from the files\n",
    "df_cham = pd.read_csv(file_path_cham)\n",
    "df_meteorites = pd.read_csv(file_path_meteorites)\n",
    "\n",
    "# Extract year and parse 'place' into city and state in df_cham\n",
    "df_cham['year'] = df_cham['date']\n",
    "df_cham[['city', 'state']] = df_cham['place'].str.extract(r'^(.*),\\s*(\\w{2,})$')\n",
    "\n",
    "# Convert the 'year' column to float for compatibility in both dataframes\n",
    "df_cham['year'] = df_cham['year'].astype(float)\n",
    "\n",
    "# Strip and capitalize the 'city' and 'state' to match format in df_meteorites\n",
    "df_cham['city'] = df_cham['city'].str.strip().str.title()\n",
    "df_cham['state'] = df_cham['state'].str.strip().str.title()\n",
    "\n",
    "# Prepare df_meteorites: capitalize the 'name' and 'State'\n",
    "df_meteorites['name'] = df_meteorites['name'].str.strip().str.title()\n",
    "df_meteorites['State'] = df_meteorites['State'].str.strip().str.title()\n",
    "\n",
    "# Preview the modified dataframes\n",
    "df_cham.head(), df_meteorites.head(), df_cham[['year', 'city', 'state']].head(), df_meteorites[['year', 'name', 'State']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cham_api_1900_1963.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'date' column to a string and extract the year\n",
    "data['date'] = data['date'].astype(str).str[:4]\n",
    "\n",
    "# Remove the 'frequency' column\n",
    "data_simplified = data.drop(columns=['frequency'])\n",
    "\n",
    "# Define a function to extract city and state from the place column\n",
    "def extract_city_state(place):\n",
    "    if pd.isna(place):\n",
    "        return pd.NA, pd.NA  # Handle NaN values\n",
    "    match = re.match(r\"^(.*?)(?:,|\\[)(.*?)(?:\\]|,|$)\", place.strip())\n",
    "    if match:\n",
    "        city = match.group(1).strip()\n",
    "        state = match.group(2).strip()\n",
    "        return city, state\n",
    "    return place, None  # Default case if no match (unlikely but safe to handle)\n",
    "\n",
    "# Apply the function to each row in the 'place' column\n",
    "city_state = data['place'].apply(extract_city_state)\n",
    "data_simplified['City'], data_simplified['State'] = zip(*city_state)\n",
    "\n",
    "# Export the cleaned dataset to a new CSV file\n",
    "data_simplified.to_csv('cleaned_cham_api_1900_1963.csv', index=False)\n",
    "\n",
    "\n",
    "# # Filter text column to only include 100-word sections containing \"meteorite\" or \"meteorites\"\n",
    "# def extract_meteorite_text(text):\n",
    "#     words = text.split()\n",
    "#     keyword_indices = [i for i, word in enumerate(words) if 'meteorite' in word.lower()]\n",
    "#     extracted_texts = []\n",
    "    \n",
    "#     for index in keyword_indices:\n",
    "#         # Calculate start and end indices for slicing 50-word sections\n",
    "#         start = max(index - 25, 0)  # Start from index-25, but not less than 0\n",
    "#         end = min(index + 25, len(words))  # End at index+25, but not more than length of words\n",
    "#         extracted_texts.append(' '.join(words[start:end]))\n",
    "    \n",
    "#     return ' '.join(extracted_texts) if extracted_texts else ''\n",
    "\n",
    "# # Apply the function to the 'text' column\n",
    "# data['text'] = data['text'].apply(extract_meteorite_text)\n",
    "\n",
    "# Define the path for the new CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "file_path1 = 'cleaned_cham_api_1900_1963.csv'\n",
    "file_path2 = 'meteorites_with_state_and_country.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Standardize the 'State' names in df1 (short forms to possible full names)\n",
    "state_abbreviations = {\n",
    "    'Tex.': 'Texas', 'Wash.': 'Washington', 'Ariz.': 'Arizona', 'Utah': 'Utah',\n",
    "    'N.Y.': 'New York', 'Calif.': 'California', 'Fla.': 'Florida', 'Mich.': 'Michigan'\n",
    "}\n",
    "df1['State'] = df1['State'].map(state_abbreviations).fillna(df1['State'])\n",
    "\n",
    "# Convert 'date' in df1 and 'year' in df2 to integer year format\n",
    "df1['Year'] = df1['date'].astype(int)\n",
    "df2['Year'] = df2['year'].astype(int)\n",
    "\n",
    "# Perform the merge based on 'Year' and 'State'\n",
    "merged_df = pd.merge(df1, df2, on=['Year', 'State'], how='inner')\n",
    "\n",
    "merged_df.to_csv('merged_meteorites_cham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# meteorite_search = requests.get(\"https://chroniclingamerica.loc.gov/search/pages/results/?date1=1756&rows=&searchType=basic&state=&date2=1800&proxtext=meteorite+found&y=0&x=0&dateFilterType=yearRange&page=1&format=json\").json()\n",
    "# meteorite_search['totalItems']\n",
    "#result = 0 mentions of meteorites landing from 1756-1800\n",
    "\n",
    "# meteorite_search = requests.get(\"https://chroniclingamerica.loc.gov/search/pages/results/?date1=1800&rows=&searchType=basic&state=&date2=1850&proxtext=meteorite+found&y=0&x=0&dateFilterType=yearRange&page=1&format=json\").json()\n",
    "# meteorite_search['totalItems']\n",
    "# result = 3 mentions of meteorites landing from 1800-1850\n",
    "\n",
    "# meteorite_search = requests.get(\"https://chroniclingamerica.loc.gov/search/pages/results/?date1=1850&rows=&searchType=basic&state=&date2=1900&proxtext=meteorite+found&y=0&x=0&dateFilterType=yearRange&page=1&format=json\").json()\n",
    "# meteorite_search['totalItems']\n",
    "#result = 466 mentions of meteorites landing from 1850-1900\n",
    "\n",
    "# meteorite_search = requests.get(\"https://chroniclingamerica.loc.gov/search/pages/results/?date1=1900&rows=&searchType=basic&state=&date2=1963&proxtext=meteorite+found&y=0&x=0&dateFilterType=yearRange&page=1&format=json\").json()\n",
    "# meteorite_search['totalItems']\n",
    "#result = 749 mentions of meteorites landing from 1900-1963\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
